// Anthropic (Claude) Provider Service
// This service handles communication with Anthropic's Claude models

import Anthropic from '@anthropic-ai/sdk';
import { BaseLLMProvider, ILLMProvider, ChatRequest, ChatChunk, ChatResponse, ModelInfo, ConnectionTestResult, TokenUsage } from './base-provider';

export class AnthropicService extends BaseLLMProvider implements ILLMProvider {
  protected metadata = {
    id: 'anthropic',
    name: 'Anthropic',
    label: 'Claude',
    icon: 'Zap',
    color: 'bg-purple-500',
    description: 'Anthropic Claude models with extended context',
    website: 'https://anthropic.com',
    supportsStreaming: true,
    supportsSystemPrompt: true,
    maxContextLength: 200000,
    requiresBaseUrl: false,
    rateLimitNotes: '4K RPM (tier 1), higher tiers available',
    models: [
      {
        id: 'claude-3-5-sonnet-20241022',
        name: 'Claude 3.5 Sonnet',
        maxTokens: 8192,
        description: 'Most capable model with vision',
        contextWindow: 200000,
        pricing: { input: 3, output: 15 }
      },
      {
        id: 'claude-3-opus-20240229', 
        name: 'Claude 3 Opus',
        maxTokens: 4096,
        description: 'Advanced reasoning',
        contextWindow: 200000,
        pricing: { input: 15, output: 75 }
      },
      {
        id: 'claude-3-sonnet-20240229',
        name: 'Claude 3 Sonnet',
        maxTokens: 4096,
        description: 'Balanced performance',
        contextWindow: 200000,
        pricing: { input: 3, output: 15 }
      },
      {
        id: 'claude-3-haiku-20240307',
        name: 'Claude 3 Haiku',
        maxTokens: 4096,
        description: 'Fastest and most compact',
        contextWindow: 200000,
        pricing: { input: 0.25, output: 1.25 }
      }
    ]
  };

  private client: Anthropic | null = null;

  constructor(apiKey: string) {
    super();
    this.client = new Anthropic({ apiKey });
  }

  async testConnection(apiKey: string, baseUrl?: string): Promise<ConnectionTestResult> {
    try {
      const testClient = new Anthropic({ 
        apiKey,
        baseURL: baseUrl // Use custom base URL if provided
      });

      // Start timer for latency measurement
      const startTime = Date.now();
      
      // Test API connectivity
      await testClient.messages.create({
        model: 'claude-3-haiku-20240307',
        max_tokens: 10,
        messages: [{ role: 'user', content: 'Hello' }]
      });
      
      const latencyMs = Date.now() - startTime;
      
      return {
        success: true,
        latencyMs,
        details: { provider: 'anthropic' }
      };
    } catch (error: any) {
      console.error('Anthropic connection test error:', error);
      return {
        success: false,
        error: error.message || 'Connection test failed'
      };
    }
  }

  async getModels(apiKey?: string): Promise<ModelInfo[]> {
    try {
      // If apiKey is provided, create a new client instance
      const client = apiKey ? new Anthropic({ apiKey }) : this.client;
      if (!client) {
        throw new Error('Anthropic client not initialized');
      }

      // Get available models from Anthropic API
      const models = await client.models.list();
      // Handle both array and object with data property
      const modelList = Array.isArray(models) ? models : (models as any).data || [];
      return modelList
        .filter((model: any) => model.id.startsWith('claude'))
        .map((model: any) => ({
          id: model.id,
          name: model.id.replace('claude-', 'Claude ').replace(/-/g, ' ').replace(/\b\w/g, (l: string) => l.toUpperCase()),
          maxTokens: this.getMaxTokensForModel(model.id),
          description: `Anthropic ${model.id} model`,
          contextWindow: 200000, // Standard for Claude models
          pricing: { input: 3, output: 15 } // Default pricing
        }));
    } catch (error) {
      console.error('Error fetching Anthropic models:', error);
      
      // Return default models as fallback
      return this.metadata.models;
    }
  }

  private getMaxTokensForModel(model: string): number {
    switch (model) {
      case 'claude-3-5-sonnet-20241022':
        return 8192;
      case 'claude-3-opus-20240229':
        return 4096;
      case 'claude-3-sonnet-20240229':
        return 4096;
      case 'claude-3-haiku-20240307':
        return 4096;
      default:
        return 4096;
    }
  }

  async streamChat(
    request: ChatRequest,
    apiKey: string,
    baseUrl?: string
  ): AsyncGenerator<ChatChunk> {
    const client = new Anthropic({
      apiKey,
      baseURL: baseUrl
    });

    const model = request.model || 'claude-3-haiku-20240307';
    const temperature = request.temperature ?? 0.7;
    const maxTokens = request.maxTokens || 4096;

    // Separate system prompt from other messages
    const systemMessage = request.messages.find(msg => msg.role === 'system');
    const otherMessages = request.messages.filter(msg => msg.role !== 'system');

    // Convert messages to Anthropic format
    const anthropicMessages = otherMessages.map(msg => ({
      role: msg.role as 'user' | 'assistant',
      content: msg.content
    }));

    const params: any = {
      model,
      messages: anthropicMessages,
      max_tokens: maxTokens,
      temperature,
      stream: true
    };

    if (systemMessage) {
      params.system = systemMessage.content;
    }

    try {
      const stream: AsyncIterable<Anthropic.MessageStreamEvent> = await client.messages.stream(params);
      
      for await (const chunk of stream) {
        if (chunk.type === 'content_block_delta' && chunk.delta?.type === 'text_delta') {
          yield { content: chunk.delta.text };
        } else if (chunk.type === 'message_delta' || chunk.type === 'message_stop') {
          // Handle end of stream
          yield { 
            content: '',
            done: true,
            finishReason: chunk.type === 'message_delta' ? (chunk as any).delta.stop_reason : chunk.type
          };
        }
      }
    } catch (error) {
      console.error('Anthropic streaming API error:', error);
      throw error;
    }
  }

  async chat(
    request: ChatRequest,
    apiKey: string,
    baseUrl?: string
  ): Promise<ChatResponse> {
    const client = new Anthropic({
      apiKey,
      baseURL: baseUrl
    });

    const model = request.model || 'claude-3-haiku-20240307';
    const temperature = request.temperature ?? 0.7;
    const maxTokens = request.maxTokens || 4096;

    // Separate system prompt from other messages
    const systemMessage = request.messages.find(msg => msg.role === 'system');
    const otherMessages = request.messages.filter(msg => msg.role !== 'system');

    // Convert messages to Anthropic format
    const anthropicMessages = otherMessages.map(msg => ({
      role: msg.role as 'user' | 'assistant',
      content: msg.content
    }));

    const params: any = {
      model,
      messages: anthropicMessages,
      max_tokens: maxTokens,
      temperature,
    };

    if (systemMessage) {
      params.system = systemMessage.content;
    }

    try {
      const response: Anthropic.Message = await client.messages.create(params);
      
      return {
        content: response.content[0].text,
        finishReason: response.stop_reason || 'stop',
        usage: {
          promptTokens: response.usage?.input_tokens,
          completionTokens: response.usage?.output_tokens,
          totalTokens: (response.usage?.input_tokens || 0) + (response.usage?.output_tokens || 0)
        }
      };
    } catch (error) {
      console.error('Anthropic API error:', error);
      throw error;
    }
  }
}

export default AnthropicService;